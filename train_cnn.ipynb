{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f6a938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_files       \n",
    "#from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "train_data = '/Users/jetcalz07/Desktop/projects/sf_dd/data/imgs/train/'\n",
    "test_data = '/Users/jetcalz07/Desktop/projects/sf_dd/data/imgs/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fafaafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read indiv image\n",
    "def get_cv2_image(path, img_rows, img_cols, color_type=1):\n",
    "    # Loading as Grayscale image\n",
    "    if color_type == 1:\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    elif color_type == 3:\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    # Reduce size\n",
    "    img = cv2.resize(img, (img_rows, img_cols)) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e82f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "classes = ['c' + str(x) for x in range(num_classes)]\n",
    "\n",
    "# Load train batch into image and label arrays\n",
    "def load_train(img_rows, img_cols, color_type=1):\n",
    "    train_imgs = []\n",
    "    train_labels = []\n",
    "    \n",
    "    # Go through each folder\n",
    "    for class_ in classes:\n",
    "        files = glob(os.path.join(train_data, class_, '*.jpg'))\n",
    "        for file in tqdm(files):\n",
    "            img = get_cv2_image(file, img_rows, img_cols, color_type)\n",
    "            train_imgs.append(img)\n",
    "            train_labels.append(class_)\n",
    "            \n",
    "    return train_imgs, train_labels\n",
    "\n",
    "\n",
    "# Split into train and val\n",
    "def normalize_and_split_train_val(img_rows, img_cols, color_type=1):\n",
    "    X, labels = load_train(img_rows, img_cols, color_type)\n",
    "    y = np_utils.to_categorical(labels, 10)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Convert dtype and reshape for batches\n",
    "    x_train = np.array(x_train, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n",
    "    x_test = np.array(x_test, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val\n",
    "    \n",
    "    \n",
    "# Same for test\n",
    "def load_test(img_rows, img_cols, color_type=1, size=200000):\n",
    "    X_test = []\n",
    "    \n",
    "    files = glob(os.path.join(test_data, '*.jpg'))\n",
    "    total = 0\n",
    "    for file in files:\n",
    "        if total >= size:\n",
    "            break\n",
    "        img = get_cv2_image(file, img_rows, img_cols, color_type)\n",
    "        X_test.append(img)\n",
    "        total += 1\n",
    "            \n",
    "    return X_test\n",
    "\n",
    "def read_and_normalize_test_data(img_rows, img_cols, color_type=1, size=200000):\n",
    "    test_data = load_test(img_rows, img_cols, color_type, size)\n",
    "    test_data = np.array(test_data, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n",
    "    \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6548899",
   "metadata": {},
   "source": [
    "#### Add normalization step and val split ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76fcd7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2489/2489 [00:03<00:00, 721.47it/s]\n",
      "100%|██████████████████████████████████████| 2267/2267 [00:03<00:00, 719.39it/s]\n",
      "100%|██████████████████████████████████████| 2317/2317 [00:03<00:00, 727.56it/s]\n",
      "100%|██████████████████████████████████████| 2346/2346 [00:03<00:00, 724.72it/s]\n",
      "100%|██████████████████████████████████████| 2326/2326 [00:03<00:00, 723.04it/s]\n",
      "100%|██████████████████████████████████████| 2312/2312 [00:03<00:00, 721.56it/s]\n",
      "100%|██████████████████████████████████████| 2325/2325 [00:03<00:00, 725.59it/s]\n",
      "100%|██████████████████████████████████████| 2002/2002 [00:02<00:00, 716.54it/s]\n",
      "100%|██████████████████████████████████████| 1911/1911 [00:02<00:00, 727.43it/s]\n",
      "100%|██████████████████████████████████████| 2129/2129 [00:02<00:00, 723.29it/s]\n",
      "100%|██████████████████████████████████████| 2489/2489 [00:03<00:00, 737.22it/s]\n",
      "100%|██████████████████████████████████████| 2267/2267 [00:03<00:00, 725.17it/s]\n",
      "100%|██████████████████████████████████████| 2317/2317 [00:03<00:00, 726.89it/s]\n",
      "100%|██████████████████████████████████████| 2346/2346 [00:03<00:00, 733.58it/s]\n",
      "100%|██████████████████████████████████████| 2326/2326 [00:03<00:00, 734.88it/s]\n",
      "100%|██████████████████████████████████████| 2312/2312 [00:03<00:00, 726.41it/s]\n",
      "100%|██████████████████████████████████████| 2325/2325 [00:03<00:00, 732.39it/s]\n",
      "100%|██████████████████████████████████████| 2002/2002 [00:02<00:00, 718.01it/s]\n",
      "100%|██████████████████████████████████████| 1911/1911 [00:02<00:00, 730.17it/s]\n",
      "100%|██████████████████████████████████████| 2129/2129 [00:02<00:00, 729.85it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np_utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [35], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m color_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m train_imgs, train_labels \u001b[38;5;241m=\u001b[39m load_train(img_rows, img_cols, color_type)\n\u001b[0;32m----> 6\u001b[0m x_train, x_val, y_train, y_val \u001b[38;5;241m=\u001b[39m normalize_and_split_train_val(img_rows, img_cols, color_type)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample Image Label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_labels[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(train_imgs[\u001b[38;5;241m0\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [34], line 23\u001b[0m, in \u001b[0;36mnormalize_and_split_train_val\u001b[0;34m(img_rows, img_cols, color_type)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_and_split_train_val\u001b[39m(img_rows, img_cols, color_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     22\u001b[0m     X, labels \u001b[38;5;241m=\u001b[39m load_train(img_rows, img_cols, color_type)\n\u001b[0;32m---> 23\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mnp_utils\u001b[49m\u001b[38;5;241m.\u001b[39mto_categorical(labels, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     24\u001b[0m     x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Convert dtype and reshape for batches\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np_utils' is not defined"
     ]
    }
   ],
   "source": [
    "img_rows = 64\n",
    "img_cols = 64\n",
    "color_type = 1\n",
    "\n",
    "train_imgs, train_labels = load_train(img_rows, img_cols, color_type)\n",
    "x_train, x_val, y_train, y_val = normalize_and_split_train_val(img_rows, img_cols, color_type)\n",
    "\n",
    "print(f\"Sample Image Label: {train_labels[0]}\")\n",
    "plt.imshow(train_imgs[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22951cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (200, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "nb_test_samples = 200\n",
    "test_files = read_and_normalize_test_data(img_rows, img_cols, color_type, nb_test_samples)\n",
    "print('Test shape:', test_files.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f65a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88bc7763",
   "metadata": {},
   "source": [
    "### Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c1f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
    "# from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5234bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac9ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcba89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6efde3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e41141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70aed5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
